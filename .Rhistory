perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
plot(perf)
# Plot Precision/Recall curve
perf <- performance(pred, measure = 'prec', x.measure = 'rec')
plot(perf)
# Plot accuracy as function of threshold
perf <- performance(pred, measure = 'acc')
plot(perf)
seq(-10,15)
2^seq(-10,15)
for (i in 2^seq(-10,15)){
svp <- ksvm(xtrain, ytrain, type='C-svc', kernel='vanilladot', C=i, scaled=c())
par(ask=T)
plot(svp, xtrain)
}
source('~/.active-rstudio-document', echo=TRUE)
xtrain
length(xtrain)
length(ytrain)
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
length(xtrain)
length(ytrain)
svp <- ksvm(xtrain, ytrain, type='C-svc', kernel='vanilladot', C=100, scaled=c())
plot(svp,data=xtrain)
for (i in 2^seq(-10,15)){
print(i)
svp <- ksvm(xtrain, ytrain, type='C-svc', kernel='vanilladot', C=i, scaled=c())
par(ask=T)
plot(svp, xtrain)
}
svp <- ksvm(xtrain, ytrain, type='C-svc', kernel='vanilladot', C=100, scaled=c())
plot(svp, xtrain)
for (i in 2^seq(-10,15)){
print(i)
svp <- ksvm(xtrain, ytrain, type='C-svc', kernel='vanilladot', C=i, scaled=c())
par(ask=T)
plot(svp, data=xtrain)
}
a <- c(1,2,3)
append(a, 4)
a
cs <- c()
errors <- c()
for (i in 2^seq(-10,15)){
svp <- ksvm(xtrain, ytrain, type='C-svc', kernel='vanilladot', C=i, scaled=c(), cross=5)
cs <- append(cs, i)
errors <- append(errors, error(svp))
}
cs
errors
plot(cs~errors)
plot(errors~cs)
x
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos <- 0 # centre of the distribution of positive examples
meanneg <- 1 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos <- matrix(rnorm(npos*p, mean=meanpos, sd=sigma), npos, p)
xneg <- matrix(rnorm(nneg*p, mean=meanneg, sd=sigma), nneg, p)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos), rep(-1, nneg)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos <- 0 # centre of the distribution of positive examples
meanneg <- 1 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos <- matrix(rnorm(npos*p, mean=meanpos, sd=sigma), npos, p)
xneg <- matrix(rnorm(nneg*p, mean=meanneg, sd=sigma), nneg, p)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos), rep(-1, nneg)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos <- -1 # centre of the distribution of positive examples
meanneg <- 1 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos <- matrix(rnorm(npos*p, mean=meanpos, sd=sigma), npos, p)
xneg <- matrix(rnorm(nneg*p, mean=meanneg, sd=sigma), nneg, p)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos), rep(-1, nneg)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
n <- 150 # Number of datapoints
p <- 4   # dimension
sigma <- 1   # variance of the distribution
meanpos <- -1 # centre of the distribution of positive examples
meanneg <- 1 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos <- matrix(rnorm(npos*p, mean=meanpos, sd=sigma), npos, p)
xneg <- matrix(rnorm(nneg*p, mean=meanneg, sd=sigma), nneg, p)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos), rep(-1, nneg)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
n <- 150 # Number of datapoints
p <- 4   # dimension
sigma <- 1   # variance of the distribution
meanpos <- -2 # centre of the distribution of positive examples
meanneg <- 2 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos <- matrix(rnorm(npos*p, mean=meanpos, sd=sigma), npos, p)
xneg <- matrix(rnorm(nneg*p, mean=meanneg, sd=sigma), nneg, p)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos), rep(-1, nneg)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
x
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos <- -2 # centre of the distribution of positive examples
meanneg <- 2 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos <- matrix(rnorm(npos*p, mean=meanpos, sd=sigma), npos, p)
xneg <- matrix(rnorm(nneg*p, mean=meanneg, sd=sigma), nneg, p)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos), rep(-1, nneg)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
x
rnorm(npos*p, mean=meanpos, sd=sigma)
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos1 <- 0 # centre of the distribution of positive examples
meanpos2 <- 3 # centre of the distribution of positive examples
meanneg1 <- 0 # centre of the distribution of negative examples
meanneg2 <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos1 <- matrix(rnorm(npos*p, mean=meanpos, sd=sigma), npos, p)
xpos1 <- matrix(rnorm(npos*p, mean=meanpos1, sd=sigma), npos, p)
xpos2 <- matrix(rnorm(npos*p, mean=meanpos2, sd=sigma), npos, p)
xpos <- rbind(xpos1,xpos2)
xpos
xneg1 <- matrix(rnorm(npos*p, mean=meanneg1, sd=sigma), xneg, p)
xneg2 <- matrix(rnorm(npos*p, mean=meanneg2, sd=sigma), xneg, p)
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos1 <- 0 # centre of the distribution of positive examples
meanpos2 <- 3 # centre of the distribution of positive examples
meanneg1 <- 0 # centre of the distribution of negative examples
meanneg2 <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos1 <- matrix(rnorm(npos*p, mean=meanpos1, sd=sigma), npos, p)
xpos2 <- matrix(rnorm(npos*p, mean=meanpos2, sd=sigma), npos, p)
xpos <- rbind(xpos1,xpos2)
xneg1 <- matrix(rnorm(npos*p, mean=meanneg1, sd=sigma), xneg, p)
xneg2 <- matrix(rnorm(npos*p, mean=meanneg2, sd=sigma), xneg, p)
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos1 <- 0 # centre of the distribution of positive examples
meanpos2 <- 3 # centre of the distribution of positive examples
meanneg1 <- 0 # centre of the distribution of negative examples
meanneg2 <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos1 <- matrix(rnorm(npos*p, mean=meanpos1, sd=sigma), npos, p)
xpos2 <- matrix(rnorm(npos*p, mean=meanpos2, sd=sigma), npos, p)
xpos <- rbind(xpos1,xpos2)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), xneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), xneg, p)
rnorm(nneg*p, mean=meanneg1, sd=sigma)
rnorm(npos*p, mean=meanpos1, sd=sigma)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
cbind(xneg1, xneg2)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
xneg1
xneg2
cbind(xneg1, xneg2)
xneg1 <- xneg[,c(1,3)]
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
xneg <- cbind(xneg1, xneg2)
xneg1 <- xneg[,c(1,3)]
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos1 <- 0 # centre of the distribution of positive examples
meanpos2 <- 3 # centre of the distribution of positive examples
meanneg1 <- 0 # centre of the distribution of negative examples
meanneg2 <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos1 <- matrix(rnorm(npos*p, mean=meanpos1, sd=sigma), npos, p)
xpos2 <- matrix(rnorm(npos*p, mean=meanpos2, sd=sigma), npos, p)
xpos <- rbind(xpos1,xpos2)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
xneg <- cbind(xneg1, xneg2)
xneg1 <- xneg[,c(1,3)]
xneg2 <- xneg[,c(2,4)]
xneg <- rbind(xneg1, xneg2)
xneg
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos*2), rep(-1, nneg*2)))
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
plot(xneg1)
plot(xneg2)
plot(xpos)
plot(xned)
plot(xneg)
xneg
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
xneg <- cbind(xneg1, xneg2)
plot(xneg)
xneg1 <- xneg[,c(1,3)]
plot(xneg1)
xneg2 <- xneg[,c(2,4)]
plot(xneg2)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg1
plot(xneg1)
npos <- round(n/2) # number of positive examples
# Generate the dataset:
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos1 <- 0 # centre of the distribution of positive examples
meanpos2 <- 3 # centre of the distribution of positive examples
meanneg1 <- 0 # centre of the distribution of negative examples
meanneg2 <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos1 <- matrix(rnorm(npos*p, mean=meanpos1, sd=sigma), npos, p)
xpos2 <- matrix(rnorm(npos*p, mean=meanpos2, sd=sigma), npos, p)
xpos <- rbind(xpos1,xpos2)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
xneg <- cbind(xneg1, xneg2)
xneg1 <- xneg[,c(1,3)]
xneg2 <- xneg[,c(2,4)]
xneg <- rbind(xneg1, xneg2)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos*2), rep(-1, nneg*2)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
```
n <- 150 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos1 <- 0 # centre of the distribution of positive examples
meanpos2 <- 3 # centre of the distribution of positive examples
meanneg1 <- 0 # centre of the distribution of negative examples
meanneg2 <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos1 <- matrix(rnorm(npos*p, mean=meanpos1, sd=sigma), npos, p)
xpos2 <- matrix(rnorm(npos*p, mean=meanpos2, sd=sigma), npos, p)
xpos <- rbind(xpos1,xpos2)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
xneg <- cbind(xneg1, xneg2)
xneg1 <- xneg[,c(1,3)]
xneg2 <- xneg[,c(2,4)]
xneg <- rbind(xneg1, xneg2)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos*2), rep(-1, nneg*2)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
n <- 75 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos1 <- 0 # centre of the distribution of positive examples
meanpos2 <- 3 # centre of the distribution of positive examples
meanneg1 <- 0 # centre of the distribution of negative examples
meanneg2 <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos1 <- matrix(rnorm(npos*p, mean=meanpos1, sd=sigma), npos, p)
xpos2 <- matrix(rnorm(npos*p, mean=meanpos2, sd=sigma), npos, p)
xpos <- rbind(xpos1,xpos2)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
xneg <- cbind(xneg1, xneg2)
xneg1 <- xneg[,c(1,3)]
xneg2 <- xneg[,c(2,4)]
xneg <- rbind(xneg1, xneg2)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos*2), rep(-1, nneg*2)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
n <- 75 # Number of datapoints
p <- 2   # dimension
sigma <- 1   # variance of the distribution
meanpos1 <- 0 # centre of the distribution of positive examples
meanpos2 <- 3 # centre of the distribution of positive examples
meanneg1 <- 0 # centre of the distribution of negative examples
meanneg2 <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos1 <- matrix(rnorm(npos*p, mean=meanpos1, sd=sigma), npos, p)
xpos2 <- matrix(rnorm(npos*p, mean=meanpos2, sd=sigma), npos, p)
xpos <- rbind(xpos1,xpos2)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
xneg <- cbind(xneg1, xneg2)
xneg1 <- xneg[,c(1,3)]
xneg2 <- xneg[,c(4,2)]
xneg <- rbind(xneg1, xneg2)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos*2), rep(-1, nneg*2)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
# Generate the dataset:
n <- 75 # Number of datapoints
p <- 2   # dimension
sigma <- 0.5   # variance of the distribution
meanpos1 <- 0 # centre of the distribution of positive examples
meanpos2 <- 3 # centre of the distribution of positive examples
meanneg1 <- 0 # centre of the distribution of negative examples
meanneg2 <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos     # number of negative examples
# Generate the positive and negative examples
xpos1 <- matrix(rnorm(npos*p, mean=meanpos1, sd=sigma), npos, p)
xpos2 <- matrix(rnorm(npos*p, mean=meanpos2, sd=sigma), npos, p)
xpos <- rbind(xpos1,xpos2)
xneg1 <- matrix(rnorm(nneg*p, mean=meanneg1, sd=sigma), nneg, p)
xneg2 <- matrix(rnorm(nneg*p, mean=meanneg2, sd=sigma), nneg, p)
xneg <- cbind(xneg1, xneg2)
xneg1 <- xneg[,c(1,3)]
xneg2 <- xneg[,c(4,2)]
xneg <- rbind(xneg1, xneg2)
x <- rbind(xpos, xneg)
# Generate the labels
y <- matrix(c(rep(1, npos*2), rep(-1, nneg*2)))
# Visualize the data
plot(x, col=ifelse(y>0,1,2))
ntrain <- round(n*0.8)  # Number of training examples
tindex <- sample(n, ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest  <- x[-tindex,]
ytrain <- y[tindex,]
ytest  <- y[-tindex,]
istrain <- rep(0, n)
istrain[tindex] <- 1
# Visualize
plot(x, col=ifelse(y > 0,1,2), pch=ifelse(istrain == 1,1,2))
svp <- ksvm(x, y, type="C-svc", kernel='rbf', kpar=list(sigma=1), C=1)
# Visualize
plot(svp, data=x)
?kernels
xtest <- c(0,0)
predict(svp, xtest)
source('~/.active-rstudio-document', echo=TRUE)
xtest
xtest <- [0,0]
xtest <- as.matrix(c(0,0))
xtest
xtest <- as.matrix(c(0,0), c(3,0))
xtest
xtest <- matrix(c(0,0,3,0), 2, 2)
xtest
predict(svp, xtest)
ypred <- xtest
ypred <- predict(svp,xtest)
ypred
ytest <- c(-1,1)
table(ytest,ypred)
library(e1071)
m <- svm(Species~., data = iris)
plot(m, iris, Petal.Width ~ Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
